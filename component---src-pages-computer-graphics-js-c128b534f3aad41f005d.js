"use strict";(self.webpackChunkportfolio=self.webpackChunkportfolio||[]).push([[593],{7979:function(e,t,a){var l=a(7294),n=a(3848);t.Z=e=>{let{color:t,image:a,title:r,year:i,link:s,skills:c,subtitle:o,video:m,modalImgs:h,description:d,descriptionFirst:u}=e;const{0:p,1:g}=(0,l.useState)(!1);return l.createElement("div",{class:""},l.createElement("button",{type:"button",class:t+" rounded w-[280px] h-[200px] lg:w-[350px] lg:h-[250px]",onClick:()=>g(!0)},l.createElement("img",{src:a,class:"max-w-[250px] max-h-[165px] lg:max-w-[290px] lg:max-h-[210px] m-auto ease-in-out duration-200 hover:scale-[1.02] hover:drop-shadow-[0px_0px_8px_rgba(0,0,0,0.4)]"})),l.createElement("p",{class:"text-md text-black text-wrap max-w-[280px] lg:max-w-[360px] font-medium hover:text-black text-center mt-2"},r),p&&l.createElement("div",{onClick:()=>g(!1),class:"flex justify-center items-center bg-gray bg-opacity-75 backdrop-blur-sm fixed min-h-[100vh] min-w-[100vw] top-0 left-0 z-20 overflow-x-hidden overflow-y-auto"},l.createElement("div",{class:"relative m-auto bg-white-smoke p-6 rounded-lg shadow-xl w-[80%] lg:w-[60%] max-h-[90vh] overflow-auto"},l.createElement("button",{type:"button",class:"text-xl md:text-2xl text-charcoal float-right relative -right-3 -top-5",onClick:()=>g(!1)},"×"),l.createElement("div",{class:"md:float-left inline w-[80%]"},l.createElement("p",{class:"font-bold text-xl"},r),l.createElement("p",{class:"text-sm"},o),l.createElement("div",{class:"md:mb-3"},c.map((e=>l.createElement(n.Z,{tag:e}))))),l.createElement("div",{class:"mb-4 md:float-right lg:inline md:text-right md:mt-2 mt-2"},i&&l.createElement("p",{class:"md:-mr-1 mb-2 lg:mb-0 inline md:block mr-2 text-sm lg:text-base md:text-right"},"Created in ",i),s&&l.createElement("a",{href:s,class:"inline text-sm lg:text-base bg-maroon text-white-smoke px-2.5 py-1 my-2 lg:inline-block rounded-md hover:bg-salmon hover:text-white-smoke"},"View code")),u?l.createElement(l.Fragment,null,l.createElement("p",{class:"clear-both"},d," "),h&&h.map((e=>l.createElement("img",{src:e,class:"px-8 py-4 max-w-[85%] m-auto clear-both"}))),m&&l.createElement(l.Fragment,null,l.createElement("div",{class:"relative pb-[50%] mt-2 clear-both"},l.createElement("iframe",{src:m,frameborder:"0",allow:"autoplay; fullscreen; picture-in-picture",allowfullscreen:!0,class:"absolute top-0 left-0 w-full h-full",title:"Volume Renderer for Medical Imaging"})),l.createElement("script",{src:"https://player.vimeo.com/api/player.js"}))):l.createElement(l.Fragment,null,h&&h.map((e=>l.createElement("img",{src:e,class:"px-8 py-4 max-w-[85%] m-auto clear-both"}))),m&&l.createElement(l.Fragment,null,l.createElement("div",{class:"relative pb-[50%] mt-2 clear-both"},l.createElement("iframe",{src:m,frameborder:"0",allow:"autoplay; fullscreen; picture-in-picture",allowfullscreen:!0,class:"absolute top-0 left-0 w-full h-full",title:"Volume Renderer for Medical Imaging"})),l.createElement("script",{src:"https://player.vimeo.com/api/player.js"})),l.createElement("p",{class:"clear-both"},d," ")))))}},6947:function(e,t,a){var l=a(7294);const n="mx-3 inline-block hover:scale-110 ease-in-out duration-200";t.Z=()=>l.createElement("div",{class:"m-auto pt-8 pb-6 bg-white-smoke sticky bottom-0"},l.createElement("div",{class:"flex justify-center"},l.createElement("a",{href:"mailto:nicolechau524@gmail.com",target:"_blank"},l.createElement("svg",{class:n,width:"25",height:"25",id:"Layer_1","data-name":"Layer 1",xmlns:"http://www.w3.org/2000/svg",viewBox:"0 0 383.23 269.46"},l.createElement("path",{fill:"#243671",d:"m383.23,241.78c-1.24,2.65-2.48,5.3-3.58,7.66-38.36-38.35-76.7-76.7-114.92-114.92,37.97-37.92,76.31-76.2,114.89-114.71,1.13,2.69,2.38,5.67,3.62,8.64v213.33Z"}),l.createElement("path",{fill:"#243671",d:"m18.69,2.52C24.63,1.6,29.72.11,34.81.1c103.89-.14,207.78-.14,311.67,0,5.48,0,10.96,1.42,16.44,2.17.19.53.37,1.06.56,1.58-1.29.97-2.71,1.8-3.84,2.92-23.22,23.17-46.44,46.33-69.58,69.59-29.44,29.59-58.91,59.15-88.12,88.97-5.84,5.96-15.61,5.89-21.4.04C127.4,111.69,74.04,58.21,20.74,4.67c-.35-.35-.68-.71-2.05-2.15Z"}),l.createElement("path",{fill:"#243671",d:"m19.01,266.86c38.98-39.03,77.22-77.31,115.68-115.81.76.68,1.6,1.35,2.36,2.11,10.15,10.13,20.23,20.34,30.45,30.4,6.51,6.41,14.67,9.61,23.63,9.42,9.45-.2,18.03-3.39,24.91-10.4,9.79-9.97,19.78-19.73,29.56-29.7,1.98-2.02,3.17-1.91,5.09.04,10.04,10.24,20.23,20.33,30.34,30.51,26.95,27.15,53.88,54.32,80.82,81.48.34.35.67.72,1.73,1.86-4.45.98-8.32,2.57-12.19,2.58-106.88.14-213.77.14-320.65,0-3.72,0-7.44-1.55-11.72-2.5Z"}),l.createElement("path",{fill:"#243671",d:"m2.96,251.3c-1.16-5.03-2.83-8.94-2.84-12.85C-.04,169.35-.04,100.24.11,31.14c0-3.94,1.59-7.87,2.45-11.81.42-.09.85-.17,1.27-.26,38.11,38.48,76.22,76.95,114.57,115.66C80.28,173.23,42.1,211.77,2.96,251.3Z"}))),l.createElement("a",{href:"https://github.com/nicole-chau",target:"_blank"},l.createElement("svg",{class:n,width:"25",height:"25",viewBox:"0 0 98 96",fill:"none",xmlns:"http://www.w3.org/2000/svg"},l.createElement("path",{"fill-rule":"evenodd","clip-rule":"evenodd",d:"M48.854 0C21.839 0 0 22 0 49.217C0 70.973 13.993 89.389 33.405 95.907C35.832 96.397 36.721 94.848 36.721 93.545C36.721 92.404 36.641 88.493 36.641 84.418C23.051 87.352 20.221 78.551 20.221 78.551C18.037 72.847 14.801 71.381 14.801 71.381C10.353 68.366 15.125 68.366 15.125 68.366C20.059 68.692 22.648 73.418 22.648 73.418C27.015 80.914 34.052 78.796 36.883 77.492C37.287 74.314 38.582 72.114 39.957 70.892C29.118 69.751 17.714 65.514 17.714 46.609C17.714 41.231 19.654 36.831 22.728 33.409C22.243 32.187 20.544 27.134 23.214 20.371C23.214 20.371 27.339 19.067 36.64 25.423C40.6221 24.3457 44.7288 23.7976 48.854 23.793C52.979 23.793 57.184 24.364 61.067 25.423C70.369 19.067 74.494 20.371 74.494 20.371C77.164 27.134 75.464 32.187 74.979 33.409C78.134 36.831 79.994 41.231 79.994 46.609C79.994 65.514 68.59 69.669 57.67 70.892C59.45 72.44 60.986 75.373 60.986 80.018C60.986 86.618 60.906 91.915 60.906 93.544C60.906 94.848 61.796 96.397 64.222 95.908C83.634 89.388 97.627 70.973 97.627 49.217C97.707 22 75.788 0 48.854 0Z",fill:"#243671"}))),l.createElement("a",{href:"https://www.linkedin.com/in/nicole-chau/",target:"_blank"},l.createElement("svg",{class:n,width:"25",height:"25",viewBox:"0 0 409 409",fill:"none",xmlns:"http://www.w3.org/2000/svg"},l.createElement("path",{d:"M-9.76585e-06 375.15V33.52C0.62999 33.39 0.71999 32.92 0.83999 32.38C3.49999 21.2 9.27999 12.38 19.32 6.25C24.08 3.35 29.23 1.87 34.31 0H373.49C373.62 0.64 374.11 0.68 374.65 0.78C383.6 2.4 391.17 6.76 397.36 13.23C405.48 21.72 408.59 32.28 408.59 43.83C408.61 150.88 408.61 257.93 408.55 364.98C408.55 368.88 408.24 372.88 407.34 376.65C405.12 385.98 400.2 393.65 392.55 399.65C385.73 404.99 378.19 408.58 369.56 408.59C259.87 408.69 150.18 408.66 40.48 408.65C26.15 408.65 15.3 402.18 7.00999 390.75C3.54999 385.99 2.16999 380.41 -0.0100098 375.14L-9.76585e-06 375.15ZM224.78 187.63C224.78 180.2 224.63 173.83 224.85 167.48C224.95 164.48 224.3 163.42 221 163.46C203.05 163.64 185.09 163.62 167.14 163.47C164.18 163.45 163.44 164.13 163.44 167.14C163.54 226.07 163.54 284.99 163.44 343.92C163.44 346.75 164.17 347.4 166.94 347.38C184.89 347.25 202.85 347.22 220.8 347.4C224.21 347.43 224.86 346.41 224.85 343.18C224.72 309.39 224.83 275.61 224.73 241.82C224.7 233.86 226.4 226.67 231.4 220.28C238.97 210.61 250.55 207.17 262.1 209.87C277.22 213.4 286.03 226.35 286 242.13C285.94 275.92 286.03 309.7 285.9 343.49C285.89 346.69 286.79 347.41 289.87 347.38C307.82 347.23 325.78 347.21 343.73 347.4C346.91 347.43 347.32 346.4 347.31 343.61C347.19 324.59 347.46 305.56 347.19 286.55C346.9 265.59 348.19 244.62 346.44 223.67C345.78 215.77 343.78 208.34 340.4 201.34C331.83 183.59 318.25 171.05 299.84 163.99C289.84 160.16 279.18 158.07 268.72 159.97C251.07 163.18 235.96 171.44 224.78 187.64V187.63ZM61.36 255.46C61.36 284.71 61.41 313.95 61.29 343.2C61.28 346.34 61.77 347.44 65.27 347.4C83.08 347.19 100.89 347.24 118.7 347.37C121.7 347.39 122.71 346.8 122.71 343.52C122.6 284.76 122.61 226 122.69 167.24C122.69 164.34 122.11 163.43 119.02 163.46C101.08 163.62 83.13 163.62 65.19 163.46C62.12 163.43 61.27 164.15 61.28 167.32C61.41 196.7 61.36 226.08 61.36 255.46ZM91.31 55.87C70.71 54.5 56.03 72.9 54.97 89.59C53.65 110.49 71.62 129.75 92.64 128.66C112.06 127.65 128.36 112.59 128.37 91.97C128.37 73.01 113.62 54.94 91.3 55.87H91.31Z",fill:"#243671"})))),l.createElement("p",{class:"text-xs block text-center mt-4 text=navy"},"© 2024 Nicole Chau"))},2024:function(e,t,a){a.r(t),a.d(t,{default:function(){return k}});var l=a(7294),n=a(4593),r=a(7979),i=a(8161),s=a(6947),c=a.p+"static/volume-renderer-926f5c3c8c5e36fd13b7e49862d9edbd.png",o=a.p+"static/path-tracer-c93affa5c49152879bc55e590227061c.png",m=a.p+"static/face-swap-4d434e3437a1524414b7aa8574e18f01.gif",h=a.p+"static/mesh-editor-3a1a96bb6738bb7f7a105f53b36785a6.png",d=a.p+"static/gpu-path-tracer-6f459a0a18ba91c54191f6cc63ffd624.gif",u=a.p+"static/beat-the-illusion-be35c9bfb4c66ecbf9ee2873b65266f6.png",p=a.p+"static/beat-the-illusion-4c1ff45e17b93dbefc09524b43342075.mp4",g=a.p+"static/pbr-shaders-6cbba2d4924f835c9f16f50f64c6db3b.png",f=a.p+"static/opengl-shaders-0863aef384ec64f4edeb9dfd65b982f9.png",E=a.p+"static/opengl-shaders-a7571cd64db6881f7eb086652fa6b885.mp4",b=a.p+"static/volume-renderer-grayscale-5e00a3fe5a64b2456f0aec374cd39701.png",v=a.p+"static/volume-renderer-rgb-ec06608eb843e2b079257e6b27478212.png";var w=()=>l.createElement("div",null,l.createElement("h2",null,"Overview"),l.createElement("p",null,"Developed as my undergraduate senior design project, this is an implementation of a volumetric renderer that can be used to view medical images (CT scans). The goal is to provide a tool for visualizing 2D medical images in 3D space and provide interactive features for transforming the data or highlighting certain parts of the data using different colors."),l.createElement("h2",null,"Features"),l.createElement("ul",null,l.createElement("li",null,"Load in DICOM dataset (directory containing series of .dcm files)"),l.createElement("li",null,"Volumetric rendering of loaded dataset (grayscale by default)"),l.createElement("li",null,"Ability to translate and rotate the dataset to view it from various angles"),l.createElement("li",null,"Option to apply a RGB transfer function to a user-defined range of Hounsfield unit values")),l.createElement("img",{src:b,alt:"volume renderer for medical imaging",class:"w-600 m-auto"}),l.createElement("img",{src:v,alt:"volume renderer for medical imaging",class:"w-600 m-auto"}),l.createElement("p",null,"The dataset loaded in the above screenshots was taken from",l.createElement("a",{href:"https://figshare.com/articles/dataset/Patient34/6265679?backTo=/collections/FUMPE/4107803"}," FigShare "),"and was uploaded by Mojtaba Masoudi."),l.createElement("h2",null,"Implementation Overview"),l.createElement("p",null,"This was implemented using Qt and C++."),l.createElement("h3",null,"Data Loading and Processing"),l.createElement("p",null,"The application allows a user to load in a series of DICOM images. Once the directory is selected, the file tags are then parsed to identify the width, height, rescale intercept and rescale slope values. For each file, the raw pixel values are read and converted to Hounsfield units (HU) with the following formula :"),l.createElement("p",{class:"text-center font-serif my-2"},"HU = pixelValue * rescaleSlope + rescaleIntercept"),l.createElement("p",null,"Note that Hounsfield units are a relative quantitative measurement of radio density used in CT scans."),l.createElement("h3",null,"Volume Rendering"),l.createElement("p",null,"The volume rendering is implemented through a ray-cast approach. For each pixel on the screen, a ray is cast from the camera origin to the pixel and through the voxel data. If the ray intersects the data volume, then the data is sampled along the ray with grid marching. For each sample, the transmittance ",l.createElement("p",{class:"font-serif inline"},"T "),"and color ",l.createElement("p",{class:"font-serif inline"},"C")," is updated based on the density (calculated from Hounsfield unit) and color at the current voxel. If the data is to be rendered using a RGB color map, then voxels with Hounsfield unit values falling within the selected range will be linearly interpolated between five predefined colors (yellow to red) to obtain the voxel color."),l.createElement("h2",null,"Third Party Libraries Used"),l.createElement("ul",null,l.createElement("li",null,"DCMTK: for loading and processing of DICOM files"),l.createElement("li",null,"ctkRangeSlider: for implementing a range slider in Qt")));var C=()=>l.createElement("div",null,l.createElement("figure",{class:"inline-block w-full m-auto mb-6"},l.createElement("img",{src:o,alt:"custom scene render 1",class:"m-auto w-1/2 clear-both"}),l.createElement("figcaption",{class:"text-center my-2 italic"},"Custom scene rendered with full light integrator; 600 x 600 px, 400 samples/pixel, max 5 recursions")),"This is a Monte Carlo path tracer implemented in C++ that renders images by computing both the direct and global illumination at each ray intersection. Multiple importance sampling is used to sample the direct lighting and russian roulette ray termination is implemented as well.",l.createElement("br",null)," ",l.createElement("br",null),"Features supported by the path tracer include:",l.createElement("ul",null,l.createElement("li",null,"Materials",l.createElement("ul",null,l.createElement("li",null,"Lambertian materials"),l.createElement("li",null,"Microfacet materials (e.g. rough mirrors)"),l.createElement("li",null,"Specular materials (e.g. glass, smooth mirrors)"))),l.createElement("li",null,"Lights",l.createElement("ul",null,l.createElement("li",null,"Area lights"),l.createElement("li",null,"Point lights"),l.createElement("li",null,"Spot lights"))),l.createElement("li",null,"Thin lens camera")));var y=()=>l.createElement("div",{class:"mt-6"},"This is a GPU-based path tracer created using OpenGL and Qt. It implements the same concepts in the Monte Carlo Path Tracer but allows for real time rendering.",l.createElement("br",null)," ",l.createElement("br",null),"Features supported by the path tracer include:",l.createElement("ul",null,l.createElement("li",null,"Materials",l.createElement("ul",null,l.createElement("li",null,"Lambertian materials"),l.createElement("li",null,"Microfacet materials (e.g. rough mirrors)"),l.createElement("li",null,"Specular materials (e.g. glass, smooth mirrors)"))),l.createElement("li",null,"Lights",l.createElement("ul",null,l.createElement("li",null,"Area lights"),l.createElement("li",null,"Environment lighting")))));var x=()=>l.createElement("div",null,l.createElement("h2",null,"Overview"),"This project was completed with two other collaborators as our final project for a computer vision class. The goal of this project is to automatically detect and swap faces in two arbitrary videos while accounting for lighting/exposure/shadows differences to produce visually appealing results. It was implemented using Python and the OpenCV library.",l.createElement("h2",null,"Technical Approach"),l.createElement("h3",null,"1. Landmark detection"),l.createElement("p",null,"We first establishing a set of corresponding feature locations in screen space between the source image and the target image. such that the eyes in the source can be correctly mapped onto the eyes in the target and so on. For this task, we utilized a DLib facial detector that maps a template of 68 facial landmarks onto a detected face."),l.createElement("h3",null,"2. Feature extraction"),l.createElement("p",null,"We define a convex hull that acts as a mask encapsulating the landmarks detected in the previous step to ensure only a small portion of the source image is retargeted onto the target image."),l.createElement("h3",null,"3. Delaunay Triangulation"),l.createElement("p",null,"In order to warp the image onto the target face accurately, we first need to triangulate the mask defined. This is completed with the Delaunay Triangulation method that ensures the areas of the triangles in this triangulation are maximally equal."),l.createElement("h3",null,"4. Warping"),l.createElement("p",null,"With triangulations for both images created, we are now able to apply affine transformations to the coordinates of the triangle vertices in the source image mask to reshape it into the shape of the mask in the target image. Each of these triangles are warped according to the transformation matrix which yields a warped version of the source mask that is ready to be overlaid on top of the target mask."),l.createElement("h3",null,"5. Face Swapping"),l.createElement("p",null,"With the source mask warped and transformed, all that is required is just to overlay the mask on top of the target image and paint in the pixels into that mask. This is done by just drawing the mask over the center of the bounding box of the target mask."),l.createElement("h3",null,"6. Gradient Domain Blending"),l.createElement("p",null,"To blend the source face with the target image more smoothly, the built-in cv2 seamlessClone() function was used to implement gradient domain blending. This allows us to make the face swap appear more natural by accounting for changes in exposure, lighting, etc."));var k=()=>l.createElement("div",{class:"h-min-screen bg-white-smoke"},l.createElement(n.q,null,l.createElement("title",null,"Nicole Chau - Computer Graphics"),l.createElement("meta",{name:"description",content:"Nicole Chau Portfolio - Computer Graphics"})),l.createElement(i.Z,{page:"/computer-graphics/"}),l.createElement("div",{class:"w-4/5 lg:min-w-3/5 m-auto h-min-screen"},l.createElement("h1",{class:"pt-16 text-navy"},"computer graphics"),l.createElement("div",{class:"flex flex-wrap justify-evenly gap-4 lg:gap-8 mt-10"},l.createElement(r.Z,{color:"bg-card-blue",image:c,title:"Volume Renderer for Medical Imaging",skills:["C++","Qt"],year:"2023",link:"https://github.com/nicole-chau/volume-renderer",video:"https://player.vimeo.com/video/844289996",description:l.createElement(w,null)}),l.createElement(r.Z,{color:"bg-card-pink",image:o,title:"Monte Carlo Path Tracer",skills:["C++","Qt"],year:"2022",description:l.createElement(C,null)}),l.createElement(r.Z,{color:"bg-card-tan",image:d,title:"GPU-based Path Tracer",skills:["OpenGL","Qt"],year:"2022",video:"https://player.vimeo.com/video/844805583",description:l.createElement(y,null)}),l.createElement(r.Z,{color:"bg-card-tan",image:m,title:"Face Swapping in Videos",skills:["Python"],year:"2022",link:"https://drive.google.com/file/d/1u_r8S4tTZFnA1SFUXDFhdajp_tIJeyeh/view?usp=sharing",video:"https://player.vimeo.com/video/844683590",description:l.createElement(x,null)}),l.createElement(r.Z,{color:"bg-card-blue",image:u,title:"'Beat the Illusion' Game",skills:["Unreal","C++"],year:"2022",description:l.createElement(l.Fragment,null,l.createElement("video",{width:"1800",controls:!0,class:"mb-8"},l.createElement("source",{src:p,type:"video/mp4"}),"Your browser does not support the video tag."),"Beat the Illusion is a puzzle game that challenges perception through optical illusions based on the shape and color of 3D geometry. Combining elements of problem-solving and memory, the player must try to “beat the illusion” and manipulate the game environment to determine which shapes are identical in actuality.",l.createElement("br",null),l.createElement("br",null),"There are three types of shapes in the game - rectangular prisms, cylinders and cones - which can be either red, green or blue. The main goal of the game is match as many shapes together as possible before losing all lives. Lives are lost when a falling shape is incorrectly or not matched. The challenge of the game is created through the illusion of different 3D shapes appearing as the same 2D shape from different angles. Players must switch the camera angle during the game to correctly identify the 3D shape. Additionally, colored lights that shine on the shapes will make the shapes' original colors appear different.",l.createElement("br",null),l.createElement("br",null),"This game was created with one other collaborater as part of a Game Design course.")}),l.createElement(r.Z,{color:"bg-card-pink",image:h,title:"Mini 3D Mesh Editor",skills:["C++","Qt"],year:"2021",video:"https://player.vimeo.com/video/644563239",description:l.createElement("div",{class:"mt-6"},"This is a mini 3D mesh editor implemented using C++ and Qt. A half-edge data structure is used to store the mesh data which includes vertices, half-edges and faces. Pointeres are also stored to relate the different mesh components and to allow for mesh traversal. Each edge is represented by two half-edges, one from each adjacent face.",l.createElement("br",null)," ",l.createElement("br",null),"Implemented features include:",l.createElement("ul",null,l.createElement("li",null,"Mesh component editing"),l.createElement("li",null,"Catmull-Clark subdivision"),l.createElement("li",null,"OBJ and JSON file loading"),l.createElement("li",null,"Mesh deformation with linear blend skinning"),l.createElement("li",null,"Planarity testing (face is automatically triangulated once it becomes non planar as a result of editing vertices)"),l.createElement("li",null,"Sharp edges and vertices (select a checkbox next to any number of vertices/edges/faces in the GUI to tag it as a sharp vertex/edge/face when the mesh is smoothed ; after subdivision all vertices/edges/faces are reset to not being sharp)")))}),l.createElement(r.Z,{color:"bg-card-tan",image:g,title:"Physically-Based Shaders",skills:["OpenGL","Qt"],year:"2022",video:"https://player.vimeo.com/video/845628830",description:l.createElement("div",{class:"mt-6"},"This is an implementation of a physically-based shader in OpenGL and Qt completed as a project for an Advanced Rendering course. This includes implementing the Cook-Torrance BRDF, Lambertian BRDF, diffuse irradiance and glossy irradiance.",l.createElement("br",null)," ",l.createElement("br",null),"References:",l.createElement("ul",null,l.createElement("li",null,l.createElement("a",{href:"https://blog.selfshadow.com/publications/s2013-shading-course/karis/s2013_pbs_epic_notes_v2.pdf"},"Real Shading in Unreal Engine 4")),l.createElement("li",null,l.createElement("a",{href:"https://learnopengl.com/PBR/IBL/Diffuse-irradiance"},"Learn OpenGL: Diffuse Irradiance")),l.createElement("li",null,l.createElement("a",{href:"https://learnopengl.com/PBR/IBL/Specular-IBL"},"Learn OpenGL: Specular IBL"))))}),l.createElement(r.Z,{color:"bg-card-blue",image:f,title:"OpenGL Shaders",skills:["OpenGL","Qt"],year:"2021",description:l.createElement(l.Fragment,null,l.createElement("video",{width:"1800",controls:!0,class:"mb-8"},l.createElement("source",{src:E,type:"video/mp4"}),"Your browser does not support the video tag."),l.createElement("p",null,"Implementation of various surface shaders and post-process shaders in OpenGL.",l.createElement("br",null),l.createElement("br",null),l.createElement("ul",null,l.createElement("li",null,"Surface shaders",l.createElement("ul",null,l.createElement("li",null,"Lambert"),l.createElement("li",null,"Blinn-Phong"),l.createElement("li",null,"Matcap"),l.createElement("li",null,"Color gradient"),l.createElement("li",null,"Vertex deformation"))),l.createElement("li",null,"Post-process shaders",l.createElement("ul",null,l.createElement("li",null,"Grayscale"),l.createElement("li",null,"Gaussian blur"),l.createElement("li",null,"Sobel"),l.createElement("li",null,"Bloom"),l.createElement("li",null,"Worley noise"))))))}))),l.createElement(s.Z,null))}}]);
//# sourceMappingURL=component---src-pages-computer-graphics-js-c128b534f3aad41f005d.js.map